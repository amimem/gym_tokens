#!/bin/zsh

# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 5 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 100 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax

# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.1 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.3 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.5 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.7 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.9 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 1 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax

# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.1 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.3 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.5 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.7 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.9 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 1 --reward 10 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax


# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 0.01 --lr_final 0.01 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 0.1 --lr_final 0.1 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 0.3 --lr_final 0.3 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 0.5 --lr_final 0.5 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 1.0 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.0001 --tmp_games 100000 --softmax

# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.01 --tmp_final 0.01 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.03 --tmp_final 0.03 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.05 --tmp_final 0.05 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.1 --tmp_final 0.1 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.3 --tmp_final 0.1 --tmp_games 100000 --softmax
# python main.py --games 10000 --env tokens-v0 --variation terminate --algo q-learning --lr 1.0 --lr_final 0.001 --seed 0 --height 11 --gamma 0.8 --reward 1 --tmp_start 0.5 --tmp_final 0.1 --tmp_games 100000 --softmax